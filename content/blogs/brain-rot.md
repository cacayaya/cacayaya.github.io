---
title: "The Collapsing Mind: How Language Topology Shapes Our Imagination"
date: 2025-10-28T21:05:36-04:00
draft: false
---
<!-- 
### human / LLM brain rot
Recently we published a paper talking about when LLM consume too much tweet junk data (short but
highly popular posts), it will get brain-rot:
- Reasoning fell by 23%
- Long-context memory dropped 30%
- Personality tests showed spikes in narcissism & psychopathy
And get this even after retraining on clean, high-quality data, the damage didn’t fully heal.

Another or more interesting thing I am thinking is about human model collapse, since so much of our human training data is now derivative/recursively generated (aggregated news, various retellings of stories across social media, etc) and seems to be having a similar effect on us as low-quality synthetic data has on LLMs. 
And another interesting paper(https://arxiv.org/pdf/2007.09560) mentions that dreaming can assit the overfitted brain. We often superised by strange talk by childrens(underfitted brain) as well as wild imagination of our dream. So yes, perhaps normal day life of an adult is a collapsed model doing things mechanically. We saw after a stage people will tend to be more stubborn and no longer want to absorb different aspects regarding the world, maybe is a sign of gradually overfitted a small set of data(your experience) and find your local minima without tempting to climb out of it.

### reason / Topology of language
语言表征的过程既有不变性,也有可变性,这种变化中的不变性质,就是语言表征的拓扑性质。
语言和物理世界处于同胚( homeomohism) 共相的关系;
语言的种种表征是基于共相的物理世界的同胚变形，即便是语言表达经过改动、变通、删减等一系列转化和修正后，语言主体仍能理解所刻画的物理世界这一恒定不变的常量。

这是一个很有趣的概念，这可能意味着人类进行语言操作的时候是在锻炼脑内进行拓扑运算，另外想到看视频和看书相比，在脑子里面进行拓扑运算的机会少很多，因为在视频里面的拓扑形式是由其几何直接显现，然而这就使人丧失了想象力，因为想象力显然也是拓扑的：想象力即是从语言的拓扑结构重建几何图像的能力。

And this will related to why short videos or various retellings of stories across social media will leads to human brain-rot, that's because those material cannot 锻炼我们进行拓扑计算的能力，同时limit我们的想象力，理解力。


而且这种情况可能正在被AI加速，在之前只是Human produce almost same information，但是AI continue produce much more 同质化内容并且充斥互联网，这可能使得普通人获得的information和锻炼更加垃圾

https://cstj.cqvip.com/Qikan/Article/Detail?id=668285357&from=Qikan_Search_Index
https://terpconnect.umd.edu/~israel/lakoff-ConTheorMetaphor.pdf
 -->

### LLMs Can Get “Brain Rot”

Recently, we published a [paper](https://arxiv.org/abs/2510.13928) examining what happens when large language models consume too much highly popular but low quality content such as viral tweets and short social posts. The results were striking: reasoning ability fell by 23 percent, long-context memory decreased by 30 percent, and simulated personality tests showed spikes in narcissism and psychopathy. Even after retraining on clean, high-quality data, the model struggled to fully recover. 

We call this phenomenon “LLM Brain Rot”, as it closely resembles what can happen to the human mind when it is continuously exposed to shallow, repetitive, and emotionally charged information.

### Humans Can Experience “Model Collapse”

The analogy also works in the opposite direction. Humans can also experience “Model Collapse”.

Children, whose brains are still underfitted, surprise us with wild imagination and unpredictable speech. Adults, by contrast, optimize for efficiency and stability. We become repetitive learners, confident in limited experience, reluctant to explore new dimensions of thought. Perhaps the everyday life of an adult mirrors a collapsed model, converged too early on a narrow set of experiences and repeating the same outputs without further learning. Over time, many people grow more stubborn and less receptive to new perspectives, a sign of slow cognitive overfitting: excessive dependence on a small personal dataset and a preference for the comfort of a local minimum rather than the effort of climbing out of it.

An interesting paper [The Overfitted Brain (2020)]((https://arxiv.org/pdf/2007.09560)) provides a compelling clue. He suggests that dreaming acts as a regularization mechanism for the overfitted mind, injecting randomness and abstraction to restore flexibility.

### The Topology of Language and the Erosion of Imagination
When we dig why human more easily got brain rot today, one interesting perspective is to study the nature of human language.

Language representation contains both variability and invariance. The stability that persists within change reflects a topological property. Language and the physical world can be viewed as homeomorphic, meaning they share a structural correspondence. Even when linguistic forms are modified, paraphrased, or reduced, they still refer to the same underlying reality.

This idea implies that understanding language requires topological computation inside the brain. When we read, we are actively performing these transformations, reshaping form while preserving meaning. Reading provides the topology, and our mind reconstructs the geometry. Watching videos, in contrast, bypasses this process. The geometric form is presented directly, leaving little room for internal reconstruction. Over time, the brain loses opportunities to practice its own topological operations. This may weaken imagination and comprehension, both of which depend on the ability to rebuild geometry from abstract representation.

Short videos and repetitive social content therefore contribute to what might be called human brain rot. They fail to exercise our topological reasoning and gradually compress our imaginative range. AI now amplifies this tendency toward linguistic centralization. By favoring the most probable words and phrases, it compresses our expressive space and makes language increasingly uniform.

